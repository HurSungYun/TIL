# Redshift 에서의 row 업데이트

보통 Redshift 의 경우는 OLAP 의 특성상 bulk insert 만 주로 하지, 개별 row 에 대한 update 는 자주 일어나지 않는다.

따라서 bulk insert 와 analysis 를 가장 잘 할 수 있는 Column Store 을 하게 된다.

그러므로 개별 row 에 대한 업데이트가 필요한 경우 성능상 문제가 생길 수 있다.

하지만, 레거시 DB의 정보가 필요한 이슈로 인해 Redshift Row 의 주기적 개별 업데이트가 필요한 일이 생겼다.

여기서 내가 포기한 것은 다음과 같다.

> 실시간 업데이트

실시간 업데이트의 경우에는 OLAP 의 특성상 그리 중요하지 않다. 따라서 실시간 업데이트를 포기했다.

업데이트의 Flow 는 다음과 같다.

1. 로그가 Redshift 에 bulk insert 되는 주기마다 update 될 항목을 batch job 을 돌려서 전체 row를 긁는다.

2. 이걸 temp table 에다가 staging 한다.

3. temp table 과 실제 table 의 primary key 를 비교하여 delete 한다.

4. temp table 전체 내용을 실제 table 에 insert 한다.

5. temp table 지워준다.

당연히 이 과정에서 트랜잭션을 걸어주어야 한다.

실제로 필요한 DB 테이블 (약 300MB) 로 테스트해보니 Redshift 에서 일어나는 과정이 30초~1분 사이에 끝났다.

아래는 실제 Redshift SQL 을 첨부한다.

```
create temp table stage_account (like accountdb.account);

select * from stage_account;

COPY accountdb.account FROM 's3://~~~~~'
IAM_ROLE 'arn:aws:iam::~~~~~~~~~~~~~~' CSV;

begin transaction;

delete from accountdb.account
using stage_account
where accountdb.account.uuid = stage_account.uuid;

insert into accountdb.account
select * from stage_account;

end transaction;

drop table stage_account;
```

100% best practice 는 아니지만 나름 나쁘지 않은 우회 방법인 것 같다.
